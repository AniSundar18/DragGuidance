**Drag-Based Image Editing using Diffusion Models**

Project Overview

This repository contains code and discusses the core-ideas behind performing Drag-Based Image Editing using Stable Diffusion. Drag-based image editing is a form of image editing where the user gives a starting and an ending point in the image and the image is transformed to satisfy those conditions. The task is non-trivial since while performing the required edit, we must make sure not to lose the identity of the original image. We use feature correspondence in order to edit the images while using mutual-self attention in order to preserve the semantic content of the image.

